{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Model parallel\n",
    "\n",
    "If model is too large to fit into a single GPU, Data Parallel method can't be operated. In this situation, we can try Model paralle, which, in contrast to DataParallel, splits a single model onto different GPUs, rather than replicating the entire model on each GPU to solve this problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = torch.nn.Linear(10, 10).to('cuda:0')\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.net2 = torch.nn.Linear(10, 5).to('cuda:1')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.net1(x.to('cuda:0')))\n",
    "        return self.net2(x.to('cuda:1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToyModel()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "outputs = model(torch.randn(20, 10))\n",
    "labels = torch.randn(20, 5).to('cuda:1')\n",
    "loss_fn(outputs, labels).backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Model Parallel to Existing Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import ResNet, Bottleneck\n",
    "\n",
    "num_classes = 1000\n",
    "\n",
    "\n",
    "class ModelParallelResNet50(ResNet):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ModelParallelResNet50, self).__init__(\n",
    "            Bottleneck, [3, 4, 6, 3], num_classes=num_classes, *args, **kwargs)\n",
    "\n",
    "        self.seq1 = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.bn1,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "\n",
    "            self.layer1,\n",
    "            self.layer2\n",
    "        ).to('cuda:0')\n",
    "\n",
    "        self.seq2 = nn.Sequential(\n",
    "            self.layer3,\n",
    "            self.layer4,\n",
    "            self.avgpool,\n",
    "        ).to('cuda:1')\n",
    "\n",
    "        self.fc.to('cuda:1')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq2(self.seq1(x).to('cuda:1'))\n",
    "        return self.fc(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "num_batches = 3\n",
    "batch_size = 120\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    model.train(True)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "    one_hot_indices = torch.LongTensor(batch_size) \\\n",
    "                           .random_(0, num_classes) \\\n",
    "                           .view(batch_size, 1)\n",
    "\n",
    "    for _ in range(num_batches):\n",
    "        # generate random inputs and labels\n",
    "        inputs = torch.randn(batch_size, 3, image_w, image_h)\n",
    "        labels = torch.zeros(batch_size, num_classes) \\\n",
    "                      .scatter_(1, one_hot_indices, 1)\n",
    "\n",
    "        # run forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to('cuda:0'))\n",
    "\n",
    "        # run backward pass\n",
    "        labels = labels.to(outputs.device)\n",
    "        loss_fn(outputs, labels).backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('Agg')\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "num_repeat = 10\n",
    "\n",
    "stmt = \"train(model)\"\n",
    "\n",
    "setup = \"model = ModelParallelResNet50()\"\n",
    "mp_run_times = timeit.repeat(\n",
    "    stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
    "mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times)\n",
    "\n",
    "setup = \"import torchvision.models as models;\" + \\\n",
    "        \"model = models.resnet50(num_classes=num_classes).to('cuda:0')\"\n",
    "rn_run_times = timeit.repeat(\n",
    "    stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
    "rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times)\n",
    "\n",
    "\n",
    "def plot(means, stds, labels, fig_name):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(np.arange(len(means)), means, yerr=stds,\n",
    "           align='center', alpha=0.5, ecolor='red', capsize=10, width=0.6)\n",
    "    ax.set_ylabel('ResNet50 Execution Time (Second)')\n",
    "    ax.set_xticks(np.arange(len(means)))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_name)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "plot([mp_mean, rn_mean],\n",
    "     [mp_std, rn_std],\n",
    "     ['Model Parallel', 'Single GPU'],\n",
    "     'mp_vs_rn.png')\n",
    "\n",
    "## Single GPU is faster than Model Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed Up by Pipelining Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineParallelResNet50(ModelParallelResNet50):\n",
    "    def __init__(self, split_size=20, *args, **kwargs):\n",
    "        super(PipelineParallelResNet50, self).__init__(*args, **kwargs)\n",
    "        self.split_size = split_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        splits = iter(x.split(self.split_size, dim=0))\n",
    "        s_next = next(splits)\n",
    "        s_prev = self.seq1(s_next).to('cuda:1')\n",
    "        ret = []\n",
    "\n",
    "        for s_next in splits:\n",
    "            # A. s_prev runs on cuda:1\n",
    "            s_prev = self.seq2(s_prev)\n",
    "            ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))\n",
    "\n",
    "            # B. s_next runs on cuda:0, which can run concurrently with A\n",
    "            s_prev = self.seq1(s_next).to('cuda:1')\n",
    "\n",
    "        s_prev = self.seq2(s_prev)\n",
    "        ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))\n",
    "\n",
    "        return torch.cat(ret)\n",
    "\n",
    "\n",
    "setup = \"model = PipelineParallelResNet50()\"\n",
    "pp_run_times = timeit.repeat(\n",
    "    stmt, setup, number=1, repeat=num_repeat, globals=globals())\n",
    "pp_mean, pp_std = np.mean(pp_run_times), np.std(pp_run_times)\n",
    "\n",
    "plot([mp_mean, rn_mean, pp_mean],\n",
    "     [mp_std, rn_std, pp_std],\n",
    "     ['Model Parallel', 'Single GPU', 'Pipelining Model Parallel'],\n",
    "     'mp_vs_rn_vs_pp.png')\n",
    "\n",
    "## Pipelining Model Parallel is fastest."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c46e020bd7951a01c610897444e7b62e6d637ce0a919f4ddb4c600ef01938ca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('codingstudy': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
